#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‰æ–¹æ³•é›†æˆå¤šè‚½å‘ç°æ¡†æ¶
åºåˆ—å˜å¼‚ + ç†æ€§è®¾è®¡ + VAEç”Ÿæˆçš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
é›†æˆäº†å¤–éƒ¨æ¨¡å‹è¿›è¡Œæœ€ç»ˆç­›é€‰å’Œæ’åº
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import json
import sys
import argparse
sys.path.append('src')

# å¯¼å…¥å„ä¸ªæ–¹æ³•æ¨¡å—
try:
    from advanced_vae_generator import VAEPeptideGenerator
except ImportError:
    print("è­¦å‘Š: VAEæ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    VAEPeptideGenerator = None

# å¯¼å…¥AIé¢„æµ‹æ¨¡å‹
try:
    from predict_peptide import PhysChemSeqEngBioBERTPredictor
except ImportError:
    print("è­¦å‘Š: AIé¢„æµ‹æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†æ— æ³•ä½¿ç”¨AIæ¨¡å‹è¿›è¡Œæœ€ç»ˆç­›é€‰")
    PhysChemSeqEngBioBERTPredictor = None

class ThreeMethodPeptideDiscovery:
    """ä¸‰æ–¹æ³•é›†æˆå¤šè‚½å‘ç°ç³»ç»Ÿ"""
    
    def __init__(self, timestamp=None, model_path=None, scaler_path=None):
        self.timestamp = timestamp or datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results_dir = f"results_three_methods_{self.timestamp}"
        self.all_candidates = []
        self.method_results = {}
        self.predictor = None
        
        # åˆ›å»ºç»“æœç›®å½•
        self._setup_directories()
        
        # åŠ è½½AIé¢„æµ‹æ¨¡å‹
        if PhysChemSeqEngBioBERTPredictor and model_path and os.path.exists(model_path):
            try:
                print("=" * 60)
                print("æ­£åœ¨åŠ è½½å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ CNNåˆ†ç±»å™¨...")
                self.predictor = PhysChemSeqEngBioBERTPredictor(model_path, scaler_path)
                print("âœ… å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ CNNåˆ†ç±»å™¨åŠ è½½æˆåŠŸï¼")
                print("=" * 60)
            except Exception as e:
                print(f"âš ï¸ è­¦å‘Š: AIé¢„æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {e}ã€‚")
                print("å°†å›é€€åˆ°åŸºäºè§„åˆ™çš„ç”Ÿç‰©å­¦è¯„åˆ†ã€‚")
                print("=" * 60)
                self.predictor = None
        else:
            print("=" * 60)
            print("âš ï¸ è­¦å‘Š: æœªæä¾›åˆ†ç±»å™¨è·¯å¾„æˆ–æ¨¡å‹ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨åŸºäºè§„åˆ™çš„è¯„åˆ†ã€‚")
            print("=" * 60)

    def _setup_directories(self):
        """è®¾ç½®ç»“æœç›®å½•ç»“æ„"""
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
        
        methods = ['sequence_variation', 'rational_design', 'vae_generation']
        for method in methods:
            method_dir = os.path.join(self.results_dir, method)
            if not os.path.exists(method_dir):
                os.makedirs(method_dir)
    
    def run_sequence_variation(self, target_count=200):
        """æ–¹æ³•1: åºåˆ—å˜å¼‚ - ä¼ ç»Ÿç©ºé—´æ¢ç´¢"""
        print("=" * 60)
        print("æ–¹æ³•1: åºåˆ—å˜å¼‚ - ä¼ ç»Ÿç©ºé—´æ¢ç´¢")
        print("=" * 60)
        
        method_dir = os.path.join(self.results_dir, 'sequence_variation')
        
        # åŠ è½½åŸå§‹æ•°æ®
        df = pd.read_csv('data/raw/120dataset.csv')
        high_activity = df[df['activity'] >= df['activity'].quantile(0.75)]
        
        # è®°å½•æ¢ç´¢å‚æ•°
        exploration_log = {
            'method': 'sequence_variation',
            'strategy': 'local_neighborhood_search',
            'timestamp': self.timestamp,
            'source_sequences': len(df),
            'high_activity_seeds': len(high_activity),
            'target_count': target_count,
            'mutation_parameters': {
                'types': ['substitute', 'insert', 'delete'],
                'max_mutations_per_sequence': 3,
                'length_range': [8, 16]
            }
        }
        
        candidates = []
        seed_sequences = high_activity['sequence'].tolist()
        
        print(f"åŸºäº {len(seed_sequences)} ä¸ªé«˜æ´»æ€§ç§å­åºåˆ—ç”Ÿæˆå˜å¼‚ä½“...")
        
        for i in range(target_count):
            if seed_sequences:
                base_seq = np.random.choice(seed_sequences)
                
                # æ‰§è¡Œ1-3ä¸ªå˜å¼‚
                num_mutations = np.random.randint(1, 4)
                mutated_seq = self._mutate_sequence(base_seq, num_mutations)
                
                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if 8 <= len(mutated_seq) <= 16 and self._is_valid_sequence(mutated_seq):
                    candidates.append({
                        'sequence': mutated_seq,
                        'method': 'sequence_variation',
                        'base_sequence': base_seq,
                        'num_mutations': num_mutations,
                        'final_length': len(mutated_seq),
                        'exploration_strategy': 'local_search'
                    })
        
        # å»é‡
        unique_candidates = self._remove_duplicates(candidates)
        
        # ä¿å­˜ç»“æœ
        self._save_method_results('sequence_variation', unique_candidates, exploration_log)
        
        print(f"âœ… åºåˆ—å˜å¼‚å®Œæˆ: ç”Ÿæˆ {len(unique_candidates)} ä¸ªç‹¬ç‰¹å€™é€‰åºåˆ—")
        self.method_results['sequence_variation'] = unique_candidates
        
        return unique_candidates
    
    def run_rational_design(self, target_count=100):
        """æ–¹æ³•2: ç†æ€§è®¾è®¡ - çŸ¥è¯†é©±åŠ¨è®¾è®¡"""
        print("=" * 60)
        print("æ–¹æ³•2: ç†æ€§è®¾è®¡ - çŸ¥è¯†é©±åŠ¨è®¾è®¡")
        print("=" * 60)
        
        method_dir = os.path.join(self.results_dir, 'rational_design')
        
        # è®¾è®¡å‚æ•°
        design_parameters = {
            'length_range': [10, 14],
            'net_charge_range': [2, 6],
            'hydrophobic_ratio_range': [0.3, 0.6],
            'aromatic_ratio_range': [0.1, 0.3],
            'key_amino_acids': ['R', 'K', 'W', 'F'],
            'design_patterns': [
                'amphipathic_helix',
                'beta_sheet',
                'random_coil'
            ]
        }
        
        exploration_log = {
            'method': 'rational_design',
            'strategy': 'knowledge_driven_design',
            'timestamp': self.timestamp,
            'design_parameters': design_parameters,
            'target_count': target_count
        }
        
        candidates = []
        
        print("åŸºäºæŠ—èŒè‚½è®¾è®¡åŸç†ç”Ÿæˆå€™é€‰åºåˆ—...")
        
        for i in range(target_count):
            # éšæœºé€‰æ‹©è®¾è®¡æ¨¡å¼
            pattern = np.random.choice(design_parameters['design_patterns'])
            
            if pattern == 'amphipathic_helix':
                sequence = self._design_amphipathic_helix()
            elif pattern == 'beta_sheet':
                sequence = self._design_beta_sheet()
            else:  # random_coil
                sequence = self._design_random_coil()
            
            if sequence and self._is_valid_sequence(sequence):
                bio_score = self._calculate_biological_score(sequence)
                
                candidates.append({
                    'sequence': sequence,
                    'method': 'rational_design',
                    'design_pattern': pattern,
                    'biological_score': bio_score,
                    'length': len(sequence),
                    'exploration_strategy': 'knowledge_guided'
                })
        
        # æŒ‰ç”Ÿç‰©å­¦è¯„åˆ†æ’åºå¹¶é€‰æ‹©æœ€ä½³å€™é€‰
        candidates.sort(key=lambda x: x['biological_score'], reverse=True)
        unique_candidates = self._remove_duplicates(candidates)
        
        # ä¿å­˜ç»“æœ
        self._save_method_results('rational_design', unique_candidates, exploration_log)
        
        print(f"âœ… ç†æ€§è®¾è®¡å®Œæˆ: ç”Ÿæˆ {len(unique_candidates)} ä¸ªè®¾è®¡åºåˆ—")
        self.method_results['rational_design'] = unique_candidates
        
        return unique_candidates
    
    def run_vae_generation(self, target_count=150, ai_score_threshold=0.5):
        """æ–¹æ³•3: VAEç”Ÿæˆ - AIé©±åŠ¨åˆ›æ–°"""
        print("=" * 60)
        print("æ–¹æ³•3: VAEç”Ÿæˆ - AIé©±åŠ¨åˆ›æ–°")
        if self.predictor:
            print("æ¨¡å¼: AIåˆ†ç±»å™¨å¼•å¯¼ç”Ÿæˆ")
        else:
            print("æ¨¡å¼: å¯å‘å¼è§„åˆ™å¼•å¯¼ç”Ÿæˆ")
        print("=" * 60)
        
        method_dir = os.path.join(self.results_dir, 'vae_generation')
        
        exploration_log = {
            'method': 'vae_generation',
            'strategy': 'ai_driven_innovation' if self.predictor else 'heuristic_fallback',
            'timestamp': self.timestamp,
            'target_count': target_count,
            'model_parameters': {
                'latent_dimension': 16,
                'training_epochs': 50,
                'temperature_sampling': 1.0,
                'feedback_enabled': True,
                'ai_predictor_integrated': bool(self.predictor),
                'ai_score_threshold': ai_score_threshold if self.predictor else 'N/A'
            }
        }
        
        candidates = []
        
        try:
            if VAEPeptideGenerator is not None:
                print("ä½¿ç”¨çœŸæ­£çš„VAEæ¨¡å‹è¿›è¡Œç”Ÿæˆ...")
                
                # å°†AIé¢„æµ‹å™¨æ³¨å…¥VAEç”Ÿæˆå™¨
                vae_generator = VAEPeptideGenerator(predictor=self.predictor)
                
                # å¿«é€Ÿè®­ç»ƒæ¨¡å¼
                print("å‡†å¤‡è®­ç»ƒæ•°æ®...")
                vae_generator.prepare_data()
                
                print("æ„å»ºå¹¶è®­ç»ƒVAEæ¨¡å‹...")
                vae_generator.build_model(latent_dim=16)
                vae_generator.train_model(epochs=30, batch_size=8)  # å¿«é€Ÿè®­ç»ƒ
                
                print("ç”Ÿæˆæ–°åºåˆ—...")
                generated = vae_generator.generate_peptides_with_feedback(
                    num_samples=target_count,
                    temperature=1.0,
                    score_threshold=ai_score_threshold
                )
                
                # è½¬æ¢æ ¼å¼
                for item in generated:
                    candidates.append({
                        'sequence': item['sequence'],
                        'method': 'vae_generation',
                        'predicted_activity': item.get('predicted_activity', 0),
                        'generation_strategy': 'ai_guided_latent_space_sampling' if self.predictor else 'heuristic_guided_sampling'
                    })
                
                exploration_log['vae_training_successful'] = True
                
            else:
                print("VAEæ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é«˜çº§å¯å‘å¼ç”Ÿæˆ...")
                candidates = self._advanced_heuristic_generation(target_count)
                exploration_log['vae_training_successful'] = False
        
        except Exception as e:
            print(f"VAEè®­ç»ƒå¤±è´¥: {e}")
            print("å›é€€åˆ°é«˜çº§å¯å‘å¼ç”Ÿæˆ...")
            candidates = self._advanced_heuristic_generation(target_count)
            exploration_log['vae_training_successful'] = False
            exploration_log['error'] = str(e)
        
        # å»é‡å’Œè´¨é‡ç­›é€‰
        unique_candidates = self._remove_duplicates(candidates)
        
        # ä¿å­˜ç»“æœ
        self._save_method_results('vae_generation', unique_candidates, exploration_log)
        
        print(f"âœ… VAEç”Ÿæˆå®Œæˆ: ç”Ÿæˆ {len(unique_candidates)} ä¸ªåˆ›æ–°åºåˆ—")
        self.method_results['vae_generation'] = unique_candidates
        
        return unique_candidates
    
    def _predict_activity_for_all_candidates(self, candidates):
        """ä½¿ç”¨åŠ è½½çš„AIæ¨¡å‹ä¸ºæ‰€æœ‰å€™é€‰åºåˆ—é¢„æµ‹æ´»æ€§"""
        if not self.predictor or not candidates:
            print("AIé¢„æµ‹å™¨ä¸å¯ç”¨æˆ–æ²¡æœ‰å€™é€‰åºåˆ—ï¼Œè·³è¿‡æœ€ç»ˆé¢„æµ‹ã€‚")
            return candidates
        
        print("=" * 60)
        print("æœ€ç»ˆç­›é€‰: ä½¿ç”¨å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ CNNåˆ†ç±»å™¨å¯¹æ‰€æœ‰å€™é€‰åºåˆ—è¿›è¡Œæ´»æ€§é¢„æµ‹...")
        print("=" * 60)
        
        sequences = [c['sequence'] for c in candidates]
        
        try:
            y_prob, _ = self.predictor.predict(sequences)
            
            # æ›´æ–°æ¯ä¸ªå€™é€‰åºåˆ—çš„é¢„æµ‹æ´»æ€§
            for i, candidate in enumerate(candidates):
                # å¦‚æœå·²æœ‰é¢„æµ‹å€¼ï¼ˆæ¥è‡ªVAEï¼‰ï¼Œåˆ™ä¿ç•™ï¼›å¦åˆ™æ›´æ–°
                candidate['predicted_activity'] = round(float(y_prob[i]), 4)
            
            print(f"âœ… å·²ä¸º {len(candidates)} ä¸ªåºåˆ—æ›´æ–°AIé¢„æµ‹æ´»æ€§ã€‚")
            
        except Exception as e:
            print(f"âš ï¸ AIé¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}ã€‚æ— æ³•æ›´æ–°é¢„æµ‹åˆ†æ•°ã€‚")
            
        return candidates

    def _mutate_sequence(self, sequence, num_mutations):
        """åºåˆ—å˜å¼‚æ“ä½œ"""
        seq_list = list(sequence)
        amino_acids = ['R', 'W', 'K', 'I', 'V', 'F', 'Y', 'L', 'A']
        
        for _ in range(num_mutations):
            mutation_type = np.random.choice(['substitute', 'insert', 'delete'])
            
            if mutation_type == 'substitute' and len(seq_list) > 0:
                pos = np.random.randint(0, len(seq_list))
                seq_list[pos] = np.random.choice(amino_acids)
                
            elif mutation_type == 'insert' and len(seq_list) < 16:
                pos = np.random.randint(0, len(seq_list) + 1)
                seq_list.insert(pos, np.random.choice(amino_acids))
                
            elif mutation_type == 'delete' and len(seq_list) > 8:
                pos = np.random.randint(0, len(seq_list))
                seq_list.pop(pos)
        
        return ''.join(seq_list)
    
    def _design_amphipathic_helix(self):
        """è®¾è®¡ä¸¤äº²æ€§èºæ—‹ç»“æ„"""
        # äº¤æ›¿æ”¾ç½®ç–æ°´æ€§å’Œäº²æ°´æ€§æ°¨åŸºé…¸
        hydrophobic = ['I', 'L', 'V', 'F', 'W', 'Y']
        hydrophilic = ['R', 'K', 'H', 'S', 'T', 'N', 'Q']
        
        length = np.random.randint(10, 15)
        sequence = ""
        
        for i in range(length):
            if i % 2 == 0:  # ç–æ°´æ€§ä½ç½®
                sequence += np.random.choice(hydrophobic)
            else:  # äº²æ°´æ€§ä½ç½®
                sequence += np.random.choice(hydrophilic)
        
        return sequence
    
    def _design_beta_sheet(self):
        """è®¾è®¡Î²æŠ˜å ç»“æ„"""
        # Î²æŠ˜å å€¾å‘çš„æ°¨åŸºé…¸
        beta_preferred = ['I', 'V', 'F', 'Y', 'W', 'K', 'R']
        
        length = np.random.randint(10, 14)
        sequence = ""
        
        for i in range(length):
            sequence += np.random.choice(beta_preferred)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ­£ç”µè·
        positive_count = sequence.count('R') + sequence.count('K')
        if positive_count < 2:
            # éšæœºæ›¿æ¢ä¸€äº›ä½ç½®ä¸ºæ­£ç”µè·æ°¨åŸºé…¸
            seq_list = list(sequence)
            for _ in range(2 - positive_count):
                pos = np.random.randint(0, len(seq_list))
                seq_list[pos] = np.random.choice(['R', 'K'])
            sequence = ''.join(seq_list)
        
        return sequence
    
    def _design_random_coil(self):
        """è®¾è®¡æ— è§„å·æ›²ç»“æ„"""
        # å¹³è¡¡çš„æ°¨åŸºé…¸ç»„æˆ
        amino_acids = ['R', 'K', 'W', 'F', 'I', 'V', 'L', 'A', 'G', 'Y']
        weights = [0.2, 0.15, 0.15, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05]
        
        length = np.random.randint(10, 14)
        sequence = ""
        
        for i in range(length):
            sequence += np.random.choice(amino_acids, p=weights)
        
        return sequence
    
    def _advanced_heuristic_generation(self, target_count):
        """é«˜çº§å¯å‘å¼ç”Ÿæˆï¼ˆVAEçš„æ›¿ä»£æ–¹æ¡ˆï¼‰"""
        print("ä½¿ç”¨é«˜çº§å¯å‘å¼æ–¹æ³•æ¨¡æ‹ŸVAEç”Ÿæˆ...")
        
        candidates = []
        
        # åŠ è½½å·²çŸ¥åºåˆ—ä½œä¸ºå‚è€ƒ
        df = pd.read_csv('data/raw/120dataset.csv')
        reference_sequences = df['sequence'].tolist()
        
        for i in range(target_count):
            # ç­–ç•¥1: ç»„åˆå·²çŸ¥æ¨¡å¼ (30%)
            if np.random.random() < 0.3:
                sequence = self._combine_sequence_patterns(reference_sequences)
                strategy = 'pattern_combination'
            
            # ç­–ç•¥2: æ¨¡æ‹Ÿæ½œåœ¨ç©ºé—´æ’å€¼ (40%)
            elif np.random.random() < 0.7:
                sequence = self._simulate_latent_interpolation(reference_sequences)
                strategy = 'simulated_interpolation'
            
            # ç­–ç•¥3: éšæœºåˆ›æ–°ç”Ÿæˆ (30%)
            else:
                sequence = self._random_innovative_generation()
                strategy = 'random_innovation'
            
            if sequence and self._is_valid_sequence(sequence):
                candidates.append({
                    'sequence': sequence,
                    'method': 'vae_generation',
                    'generation_strategy': strategy,
                    'predicted_activity': self._calculate_biological_score(sequence) / 100,
                    'exploration_strategy': 'heuristic_simulation'
                })
        
        return candidates
    
    def _combine_sequence_patterns(self, reference_sequences):
        """ç»„åˆå·²çŸ¥åºåˆ—æ¨¡å¼"""
        # éšæœºé€‰æ‹©2-3ä¸ªå‚è€ƒåºåˆ—
        selected = np.random.choice(reference_sequences, size=min(3, len(reference_sequences)), replace=False)
        
        # æå–ç‰‡æ®µå¹¶ç»„åˆ
        fragments = []
        for seq in selected:
            start = np.random.randint(0, max(1, len(seq) - 3))
            end = start + np.random.randint(3, min(6, len(seq) - start + 1))
            fragments.append(seq[start:end])
        
        # ç»„åˆç‰‡æ®µ
        combined = ''.join(fragments)
        
        # è°ƒæ•´é•¿åº¦
        if len(combined) > 16:
            combined = combined[:16]
        elif len(combined) < 8:
            # å¡«å……åˆ°æœ€å°é•¿åº¦
            amino_acids = ['R', 'K', 'W', 'F', 'I', 'V']
            while len(combined) < 8:
                combined += np.random.choice(amino_acids)
        
        return combined
    
    def _simulate_latent_interpolation(self, reference_sequences):
        """æ¨¡æ‹Ÿæ½œåœ¨ç©ºé—´æ’å€¼"""
        # é€‰æ‹©ä¸¤ä¸ªå‚è€ƒåºåˆ—
        seq1, seq2 = np.random.choice(reference_sequences, size=2, replace=False)
        
        # è®¡ç®—"æ’å€¼"åºåˆ—
        max_len = max(len(seq1), len(seq2))
        min_len = min(len(seq1), len(seq2))
        
        # éšæœºé€‰æ‹©æ’å€¼æ¯”ä¾‹
        alpha = np.random.random()
        
        # ç”Ÿæˆæ’å€¼é•¿åº¦
        interp_length = int(min_len + alpha * (max_len - min_len))
        interp_length = max(8, min(16, interp_length))
        
        # æ„å»ºæ’å€¼åºåˆ—
        sequence = ""
        for i in range(interp_length):
            # ä»ä¸¤ä¸ªåºåˆ—ä¸­é€‰æ‹©æ°¨åŸºé…¸
            pos1 = min(i, len(seq1) - 1)
            pos2 = min(i, len(seq2) - 1)
            
            if np.random.random() < alpha:
                if pos1 < len(seq1):
                    sequence += seq1[pos1]
                else:
                    sequence += seq2[pos2]
            else:
                if pos2 < len(seq2):
                    sequence += seq2[pos2]
                else:
                    sequence += seq1[pos1]
        
        return sequence
    
    def _random_innovative_generation(self):
        """éšæœºåˆ›æ–°ç”Ÿæˆ"""
        # å®Œå…¨éšæœºç”Ÿæˆï¼Œä½†éµå¾ªæŠ—èŒè‚½çš„åŸºæœ¬è§„å¾‹
        amino_acids = ['R', 'K', 'H', 'W', 'F', 'Y', 'I', 'V', 'L', 'A', 'G']
        weights = [0.25, 0.2, 0.05, 0.15, 0.1, 0.05, 0.08, 0.05, 0.03, 0.02, 0.02]
        
        length = np.random.randint(10, 15)
        sequence = ""
        
        for i in range(length):
            sequence += np.random.choice(amino_acids, p=weights)
        
        return sequence
    
    def _calculate_biological_score(self, sequence):
        """è®¡ç®—ç”Ÿç‰©å­¦è¯„åˆ†"""
        score = 0
        length = len(sequence)
        
        # å‡€ç”µè·
        positive = sequence.count('R') + sequence.count('K') + sequence.count('H')
        negative = sequence.count('D') + sequence.count('E')
        net_charge = positive - negative
        
        if 2 <= net_charge <= 6:
            score += 25
        elif 1 <= net_charge <= 8:
            score += 15
        
        # ç–æ°´æ€§
        hydrophobic = sum(sequence.count(aa) for aa in 'ILMFWYV')
        hydrophobic_ratio = hydrophobic / length
        
        if 0.3 <= hydrophobic_ratio <= 0.6:
            score += 20
        elif 0.2 <= hydrophobic_ratio <= 0.7:
            score += 15
        
        # èŠ³é¦™æ—æ°¨åŸºé…¸
        aromatic = sequence.count('F') + sequence.count('W') + sequence.count('Y')
        if aromatic >= 1:
            score += 15
        
        # é•¿åº¦ä¼˜åŒ–
        if 10 <= length <= 14:
            score += 15
        elif 8 <= length <= 16:
            score += 10
        
        # å…³é”®æ°¨åŸºé…¸
        if 'R' in sequence:
            score += 10
        if 'W' in sequence:
            score += 8
        
        return score
    
    def _is_valid_sequence(self, sequence):
        """æ£€æŸ¥åºåˆ—æœ‰æ•ˆæ€§"""
        if not sequence or len(sequence) < 6 or len(sequence) > 20:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡å‡†æ°¨åŸºé…¸
        standard_aa = set('ACDEFGHIKLMNPQRSTVWY')
        if not all(aa in standard_aa for aa in sequence.upper()):
            return False
        
        # æ£€æŸ¥å¤šæ ·æ€§
        if len(set(sequence)) < 3:
            return False
            
        return True

    def run_discovery_pipeline(self, sv_count=200, rd_count=100, vae_count=150):
        """è¿è¡Œå®Œæ•´çš„å¤šè‚½å‘ç°æµç¨‹"""
        print("ğŸš€ å¼€å§‹ä¸‰æ–¹æ³•é›†æˆå¤šè‚½å‘ç°æµç¨‹...")
        
        # è¿è¡Œå„ä¸ªç”Ÿæˆæ–¹æ³•
        sv_candidates = self.run_sequence_variation(target_count=sv_count)
        rd_candidates = self.run_rational_design(target_count=rd_count)
        vae_candidates = self.run_vae_generation(target_count=vae_count)
        
        # åˆå¹¶æ‰€æœ‰å€™é€‰åºåˆ—
        self.all_candidates.extend(sv_candidates)
        self.all_candidates.extend(rd_candidates)
        self.all_candidates.extend(vae_candidates)
        
        # ä½¿ç”¨AIæ¨¡å‹å¯¹æ‰€æœ‰å€™é€‰åºåˆ—è¿›è¡Œæœ€ç»ˆé¢„æµ‹å’Œè¯„åˆ†
        self.all_candidates = self._predict_activity_for_all_candidates(self.all_candidates)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report()
        
        print("=" * 60)
        print("ğŸ‰ å¤šè‚½å‘ç°æµç¨‹å…¨éƒ¨å®Œæˆï¼")
        print(f"æœ€ç»ˆç»“æœä¿å­˜åœ¨: {self.results_dir}")
        print("=" * 60)

    def _save_final_results(self):
        """ä¿å­˜æœ€ç»ˆå€™é€‰ç»“æœ"""
        final_df = pd.DataFrame(self.all_candidates)
        
        # ç¡®ä¿åˆ—å­˜åœ¨
        if 'biological_score' not in final_df.columns:
            final_df['biological_score'] = final_df['sequence'].apply(self._calculate_biological_score)
        if 'predicted_activity' not in final_df.columns:
            final_df['predicted_activity'] = 0.0

        # æ’åºï¼šä¼˜å…ˆä½¿ç”¨AIé¢„æµ‹åˆ†ï¼Œå¦åˆ™ä½¿ç”¨ç”Ÿç‰©å­¦è§„åˆ™åˆ†
        sort_key = 'predicted_activity' if self.predictor else 'biological_score'
        final_df = final_df.sort_values(by=sort_key, ascending=False)
        
        # ä¿å­˜æœ€ç»ˆå€™é€‰åˆ—è¡¨
        final_csv_path = os.path.join(self.results_dir, f"final_predicted_candidates_{self.timestamp}.csv")
        final_df.to_csv(final_csv_path, index=False)
        
        print(f"ğŸ’¾ æœ€ç»ˆå€™é€‰åˆ—è¡¨å·²ä¿å­˜: {final_csv_path}")

    def _generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        report_path = os.path.join(self.results_dir, f"peptide_discovery_report_{self.timestamp}.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# ä¸‰æ–¹æ³•é›†æˆå¤šè‚½å‘ç°æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"**è¿è¡Œæ ‡è¯†**: {self.timestamp}\n")
            if self.predictor:
                f.write(f"**AIç­›é€‰æ¨¡å‹**: {os.path.basename(self.predictor.model.name)}\n")
            else:
                f.write(f"**AIç­›é€‰æ¨¡å‹**: æœªä½¿ç”¨\n")
            f.write("\n## æ–¹æ³•æ¦‚è¿°\n\n")
            f.write("æœ¬æ¬¡å‘ç°é‡‡ç”¨ä¸‰ç§äº’è¡¥çš„æ¢ç´¢ç­–ç•¥:\n\n")
            f.write("1. **åºåˆ—å˜å¼‚**: åŸºäºå·²çŸ¥é«˜æ´»æ€§åºåˆ—çš„å±€éƒ¨æ¢ç´¢\n")
            f.write("2. **ç†æ€§è®¾è®¡**: åŸºäºç”Ÿç‰©å­¦çŸ¥è¯†çš„å®šå‘è®¾è®¡\n")
            f.write(f"3. **VAEç”Ÿæˆ**: {'AIåˆ†ç±»å™¨å¼•å¯¼çš„' if self.predictor else 'å¯å‘å¼è§„åˆ™å¼•å¯¼çš„'}åˆ›æ–°åºåˆ—å‘ç°\n\n")
            
            # å†™å…¥å„æ–¹æ³•çš„ç»“æœ
            for method, candidates in self.method_results.items():
                f.write(f"### {method.replace('_', ' ').title()}\n\n")
                f.write(f"- ç”Ÿæˆåºåˆ—æ•°: {len(candidates)}\n")
                
                df = pd.DataFrame(candidates)
                if not df.empty:
                    avg_len = df['sequence'].apply(len).mean()
                    f.write(f"- å¹³å‡é•¿åº¦: {avg_len:.1f}\n")
                    f.write(f"- ç‹¬ç‰¹åºåˆ—æ•°: {df['sequence'].nunique()}\n\n")
                    
                    # æ’åºå¹¶é€‰æ‹©Top 5
                    sort_key = 'predicted_activity' if 'predicted_activity' in df.columns and self.predictor else 'biological_score'
                    if sort_key in df.columns:
                        top_5 = df.sort_values(by=sort_key, ascending=False).head(5)
                    else:
                        top_5 = df.head(5)

                    f.write(f"**Top 5 åºåˆ—**:\n\n")
                    for i, row in top_5.iterrows():
                        score = row.get(sort_key, 'N/A')
                        score_str = f"{score:.4f}" if isinstance(score, float) else str(score)
                        f.write(f"{i+1}. `{row['sequence']}` (è¯„åˆ†: {score_str})\n")
                f.write("\n")
            
            f.write("## å®éªŒå»ºè®®\n\n")
            f.write("å»ºè®®ä¼˜å…ˆåˆæˆå’Œæµ‹è¯•AIé¢„æµ‹æ´»æ€§æ¦‚ç‡é«˜æˆ–ç”Ÿç‰©å­¦è¯„åˆ†â‰¥70çš„å€™é€‰åºåˆ—ï¼Œè¿™äº›åºåˆ—åœ¨ç†è®ºä¸Šå…·æœ‰è‰¯å¥½çš„æŠ—èŒæ½œåŠ›ã€‚\n\n")
            f.write("è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹å„æ–¹æ³•çš„å­ç›®å½•å’ŒCSVæ–‡ä»¶ã€‚\n")
            
        print(f"âœ… ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

    def _remove_duplicates(self, candidates):
        """å»é™¤é‡å¤åºåˆ—"""
        seen_sequences = set()
        unique_candidates = []
        
        for candidate in candidates:
            sequence = candidate['sequence']
            if sequence not in seen_sequences:
                seen_sequences.add(sequence)
                unique_candidates.append(candidate)
        
        return unique_candidates
    
    def _save_method_results(self, method_name, candidates, exploration_log):
        """ä¿å­˜å•ä¸ªæ–¹æ³•çš„ç»“æœ"""
        method_dir = os.path.join(self.results_dir, method_name)
        
        # ä¿å­˜å€™é€‰åºåˆ—
        df = pd.DataFrame(candidates)
        csv_path = os.path.join(method_dir, f"{method_name}_candidates_{self.timestamp}.csv")
        df.to_csv(csv_path, index=False)
        
        # ä¿å­˜æ¢ç´¢æ—¥å¿—
        log_path = os.path.join(method_dir, f"{method_name}_log_{self.timestamp}.json")
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(exploration_log, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… {method_name} ç»“æœå·²ä¿å­˜åˆ°: {method_dir}")

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¸‰æ–¹æ³•é›†æˆå¤šè‚½å‘ç°æ¡†æ¶')
    parser.add_argument('--sv_count', type=int, default=150, help='åºåˆ—å˜å¼‚ç”Ÿæˆæ•°é‡')
    parser.add_argument('--rd_count', type=int, default=80, help='ç†æ€§è®¾è®¡ç”Ÿæˆæ•°é‡')
    parser.add_argument('--vae_count', type=int, default=120, help='VAEç”Ÿæˆæ•°é‡')
    parser.add_argument('--model_path', type=str, 
                        default='results/physchem_seqeng_biobert_dl_rawseq/best_physchem_seqeng_biobert_rawseq_classification.h5', 
                        help='AIæ´»æ€§é¢„æµ‹æ¨¡å‹è·¯å¾„ (.h5æ–‡ä»¶)')
    parser.add_argument('--scaler_path', type=str, default=None, 
                        help='AIæ¨¡å‹æ ‡å‡†åŒ–å™¨è·¯å¾„ (.pklæ–‡ä»¶)ï¼Œå¯é€‰ï¼Œä¼šè‡ªåŠ¨æŸ¥æ‰¾')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å‘ç°ç³»ç»Ÿï¼Œå¹¶ä¼ å…¥AIæ¨¡å‹è·¯å¾„
    discovery_system = ThreeMethodPeptideDiscovery(
        model_path=args.model_path,
        scaler_path=args.scaler_path
    )
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    discovery_system.run_discovery_pipeline(
        sv_count=args.sv_count,
        rd_count=args.rd_count,
        vae_count=args.vae_count
    )

if __name__ == "__main__":
    main()
