#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šè‚½å‘ç°ç»“æœå¿«é€Ÿåˆ†æå·¥å…·
ä¸€é”®ç”Ÿæˆå…¨é¢çš„ç»“æœåˆ†ææŠ¥å‘Š
"""

import pandas as pd
import numpy as np
from collections import Counter
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os

class PeptideResultAnalyzer:
    """å¤šè‚½ç»“æœåˆ†æå™¨"""
    
    def __init__(self, results_dir):
        self.results_dir = results_dir
        self.seq_var_df = None
        self.rational_df = None
        self.vae_df = None
        self.combined_df = None
        
    def load_data(self):
        """åŠ è½½ä¸‰ç§æ–¹æ³•çš„ç»“æœæ•°æ®"""
        try:
            import glob
            
            # é¦–å…ˆå°è¯•åŠ è½½æœ€ç»ˆç»¼åˆç»“æœæ–‡ä»¶ï¼ˆåŒ…å«AIé¢„æµ‹å¾—åˆ†ï¼‰
            final_files = glob.glob(f'{self.results_dir}/final_predicted_candidates*.csv')
            
            if final_files:
                print("ğŸ¯ å‘ç°æœ€ç»ˆç»¼åˆç»“æœæ–‡ä»¶ï¼Œä½¿ç”¨AIé¢„æµ‹å¾—åˆ†è¿›è¡Œåˆ†æ...")
                self.combined_df = pd.read_csv(final_files[0])
                
                # åˆ†ç¦»å„æ–¹æ³•çš„æ•°æ®
                self.seq_var_df = self.combined_df[self.combined_df['method'] == 'sequence_variation'].copy()
                self.rational_df = self.combined_df[self.combined_df['method'].str.contains('rational_design')].copy()
                self.vae_df = self.combined_df[self.combined_df['method'] == 'vae_generation'].copy()
                
                print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ (æ¥æº: {final_files[0]}):")
                print(f"  åºåˆ—å˜å¼‚: {len(self.seq_var_df)} åºåˆ—")
                print(f"  ç†æ€§è®¾è®¡: {len(self.rational_df)} åºåˆ—") 
                print(f"  VAEç”Ÿæˆ: {len(self.vae_df)} åºåˆ—")
                print(f"  æ€»è®¡: {len(self.combined_df)} åºåˆ—")
                
                # æ£€æŸ¥AIé¢„æµ‹å¾—åˆ†
                if 'predicted_activity' in self.combined_df.columns:
                    ai_scores = self.combined_df['predicted_activity'].dropna()
                    print(f"ğŸ“Š AIé¢„æµ‹å¾—åˆ†ç»Ÿè®¡:")
                    print(f"  å¹³å‡å¾—åˆ†: {ai_scores.mean():.3f}")
                    print(f"  é«˜åˆ†åºåˆ— (>0.8): {sum(ai_scores > 0.8)} ä¸ª")
                    print(f"  ä¸­åˆ†åºåˆ— (0.6-0.8): {sum((ai_scores >= 0.6) & (ai_scores <= 0.8))} ä¸ª")
                    print(f"  ä½åˆ†åºåˆ— (<0.6): {sum(ai_scores < 0.6)} ä¸ª")
                
            else:
                # å›é€€åˆ°åŸæ¥çš„æ–¹æ³•ï¼šåˆ†åˆ«åŠ è½½ä¸‰ä¸ªå­ç›®å½•
                print("âš ï¸ æœªæ‰¾åˆ°æœ€ç»ˆç»¼åˆæ–‡ä»¶ï¼Œå›é€€åˆ°åˆ†åˆ«åŠ è½½å­ç›®å½•...")
                
                seq_var_files = glob.glob(f'{self.results_dir}/sequence_variation/*candidates*.csv')
                rational_files = glob.glob(f'{self.results_dir}/rational_design/*candidates*.csv')
                vae_files = glob.glob(f'{self.results_dir}/vae_generation/*candidates*.csv')
                
                if not seq_var_files:
                    raise FileNotFoundError(f"æœªæ‰¾åˆ°åºåˆ—å˜å¼‚ç»“æœæ–‡ä»¶: {self.results_dir}/sequence_variation/")
                if not rational_files:
                    raise FileNotFoundError(f"æœªæ‰¾åˆ°ç†æ€§è®¾è®¡ç»“æœæ–‡ä»¶: {self.results_dir}/rational_design/")
                if not vae_files:
                    raise FileNotFoundError(f"æœªæ‰¾åˆ°VAEç”Ÿæˆç»“æœæ–‡ä»¶: {self.results_dir}/vae_generation/")
                
                # åŠ è½½æ•°æ®
                self.seq_var_df = pd.read_csv(seq_var_files[0])
                self.rational_df = pd.read_csv(rational_files[0])
                self.vae_df = pd.read_csv(vae_files[0])
                
                # æ·»åŠ æ–¹æ³•æ ‡è¯†åˆ—
                self.seq_var_df['method'] = 'sequence_variation'
                self.rational_df['method'] = 'rational_design'
                self.vae_df['method'] = 'vae_generation'
                
                # åˆå¹¶æ‰€æœ‰æ•°æ®
                self.combined_df = pd.concat([self.seq_var_df, self.rational_df, self.vae_df], ignore_index=True)
                
                print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
                print(f"  åºåˆ—å˜å¼‚: {len(self.seq_var_df)} åºåˆ— ({seq_var_files[0]})")
                print(f"  ç†æ€§è®¾è®¡: {len(self.rational_df)} åºåˆ— ({rational_files[0]})")
                print(f"  VAEç”Ÿæˆ: {len(self.vae_df)} åºåˆ— ({vae_files[0]})")
                print(f"  æ€»è®¡: {len(self.combined_df)} åºåˆ—")
                
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
        return True
    
    def analyze_amino_acid_usage(self):
        """åˆ†ææ°¨åŸºé…¸ä½¿ç”¨æ¨¡å¼"""
        print("\n" + "="*60)
        print("æ°¨åŸºé…¸ä½¿ç”¨æ¨¡å¼åˆ†æ")
        print("="*60)
        
        def get_aa_frequency(df, method_name):
            all_sequences = ''.join(df['sequence'].tolist())
            aa_counts = Counter(all_sequences)
            total_aas = len(all_sequences)
            
            print(f"\nğŸ”¸ {method_name}")
            print(f"æ€»æ°¨åŸºé…¸æ•°: {total_aas}")
            print("Top 8 æ°¨åŸºé…¸é¢‘ç‡:")
            
            for aa, count in aa_counts.most_common(8):
                percentage = count / total_aas * 100
                print(f"  {aa}: {percentage:5.1f}% ({count:3d})")
            
            return aa_counts
        
        seq_var_freq = get_aa_frequency(self.seq_var_df, "åºåˆ—å˜å¼‚")
        rational_freq = get_aa_frequency(self.rational_df, "ç†æ€§è®¾è®¡")
        vae_freq = get_aa_frequency(self.vae_df, "VAEç”Ÿæˆ")
        
        return seq_var_freq, rational_freq, vae_freq
    
    def analyze_sequence_properties(self):
        """åˆ†æåºåˆ—ç‰©ç†åŒ–å­¦æ€§è´¨"""
        print("\n" + "="*60)
        print("åºåˆ—ç‰©ç†åŒ–å­¦æ€§è´¨åˆ†æ")
        print("="*60)
        
        def calculate_properties(df, method_name):
            lengths = df['sequence'].apply(len)
            charges = df['sequence'].apply(self._calculate_net_charge)
            hydrophobic_ratios = df['sequence'].apply(self._calculate_hydrophobic_ratio)
            aromatic_ratios = df['sequence'].apply(self._calculate_aromatic_ratio)
            
            print(f"\nğŸ”¸ {method_name}")
            print(f"é•¿åº¦åˆ†å¸ƒ: {lengths.min()}-{lengths.max()}, å¹³å‡: {lengths.mean():.1f}")
            print(f"å‡€ç”µè·: {charges.min()}-{charges.max()}, å¹³å‡: {charges.mean():.1f}")
            print(f"ç–æ°´æ€§æ¯”ä¾‹: {hydrophobic_ratios.min():.2f}-{hydrophobic_ratios.max():.2f}, å¹³å‡: {hydrophobic_ratios.mean():.2f}")
            print(f"èŠ³é¦™æ€§æ¯”ä¾‹: {aromatic_ratios.min():.2f}-{aromatic_ratios.max():.2f}, å¹³å‡: {aromatic_ratios.mean():.2f}")
            
            return {
                'lengths': lengths,
                'charges': charges, 
                'hydrophobic_ratios': hydrophobic_ratios,
                'aromatic_ratios': aromatic_ratios
            }
        
        seq_var_props = calculate_properties(self.seq_var_df, "åºåˆ—å˜å¼‚")
        rational_props = calculate_properties(self.rational_df, "ç†æ€§è®¾è®¡")
        vae_props = calculate_properties(self.vae_df, "VAEç”Ÿæˆ")
        
        return seq_var_props, rational_props, vae_props
    
    def find_top_candidates(self, top_n=10):
        """å¯»æ‰¾å„æ–¹æ³•çš„é¡¶çº§å€™é€‰åºåˆ—"""
        print("\n" + "="*60)
        print(f"Top {top_n} å€™é€‰åºåˆ—åˆ†æ")
        print("="*60)
        
        # æ£€æŸ¥å¯ç”¨çš„è¯„åˆ†åˆ—
        print("ğŸ” å¯ç”¨è¯„åˆ†åˆ—:")
        available_cols = list(self.combined_df.columns)
        score_cols = [col for col in available_cols if any(keyword in col.lower() 
                     for keyword in ['score', 'activity', 'prediction', 'probability'])]
        print(f"   {score_cols}")
        
        # ä¼˜å…ˆä½¿ç”¨AIé¢„æµ‹å¾—åˆ†
        if 'predicted_activity' in self.combined_df.columns:
            primary_score = 'predicted_activity'
            score_name = "AIé¢„æµ‹æ´»æ€§"
            print(f"âœ… ä½¿ç”¨ä¸»è¦è¯„åˆ†æ ‡å‡†: {score_name}")
        elif 'biological_score' in self.combined_df.columns:
            primary_score = 'biological_score'
            score_name = "ç”Ÿç‰©å­¦è¯„åˆ†"
            print(f"âš ï¸ ä½¿ç”¨å¤‡ç”¨è¯„åˆ†æ ‡å‡†: {score_name}")
        else:
            primary_score = None
            score_name = "æ— ç»Ÿä¸€è¯„åˆ†"
            print(f"âŒ æœªæ‰¾åˆ°ç»Ÿä¸€è¯„åˆ†æ ‡å‡†")
        
        for method in ['sequence_variation', 'rational_design', 'vae_generation']:
            # å¤„ç†ç†æ€§è®¾è®¡çš„æ–¹æ³•åå˜ä½“
            if method == 'rational_design':
                method_df = self.combined_df[self.combined_df['method'].str.contains('rational_design')]
                method_display = "ç†æ€§è®¾è®¡"
            elif method == 'sequence_variation':
                method_df = self.combined_df[self.combined_df['method'] == method]
                method_display = "åºåˆ—å˜å¼‚"
            elif method == 'vae_generation':
                method_df = self.combined_df[self.combined_df['method'] == method]
                method_display = "VAEç”Ÿæˆ"
            
            if len(method_df) == 0:
                print(f"\nğŸ”¸ {method_display}: æ— æ•°æ®")
                continue
                
            print(f"\nğŸ”¸ {method_display} Top {top_n}:")
            print(f"   æ€»åºåˆ—æ•°: {len(method_df)}")
            
            if primary_score and primary_score in method_df.columns:
                # ä½¿ç”¨ä¸»è¦è¯„åˆ†æ’åº
                valid_scores = method_df[method_df[primary_score].notna()]
                if len(valid_scores) > 0:
                    top_sequences = valid_scores.nlargest(top_n, primary_score)
                    print(f"   æ’åºä¾æ®: {score_name}")
                else:
                    top_sequences = method_df.head(top_n)
                    print(f"   æ’åºä¾æ®: åŸå§‹é¡ºåº (æ— æœ‰æ•ˆ{score_name})")
            else:
                # å›é€€åˆ°å…¶ä»–è¯„åˆ†æ ‡å‡†
                if 'biological_score' in method_df.columns:
                    top_sequences = method_df.nlargest(top_n, 'biological_score')
                    print(f"   æ’åºä¾æ®: ç”Ÿç‰©å­¦è¯„åˆ†")
                else:
                    top_sequences = method_df.head(top_n)
                    print(f"   æ’åºä¾æ®: åŸå§‹é¡ºåº")
            
            # æ˜¾ç¤ºTopåºåˆ—
            for i, (_, row) in enumerate(top_sequences.iterrows(), 1):
                seq = row['sequence']
                
                # æ”¶é›†æ‰€æœ‰å¯ç”¨å¾—åˆ†
                scores_info = []
                if 'predicted_activity' in row and pd.notna(row['predicted_activity']):
                    scores_info.append(f"AI: {row['predicted_activity']:.3f}")
                if 'biological_score' in row and pd.notna(row['biological_score']):
                    scores_info.append(f"Bio: {row['biological_score']:.1f}")
                
                scores_str = ", ".join(scores_info) if scores_info else "æ— è¯„åˆ†"
                print(f"  {i:2d}. {seq:<20} ({scores_str})")
        
        # å…¨å±€Topå€™é€‰ï¼ˆè·¨æ–¹æ³•ï¼‰
        if primary_score and primary_score in self.combined_df.columns:
            print(f"\nğŸ† å…¨å±€Top {top_n} å€™é€‰åºåˆ— (åŸºäº{score_name}):")
            valid_global = self.combined_df[self.combined_df[primary_score].notna()]
            if len(valid_global) > 0:
                global_top = valid_global.nlargest(top_n, primary_score)
                for i, (_, row) in enumerate(global_top.iterrows(), 1):
                    seq = row['sequence']
                    method = row['method']
                    score = row[primary_score]
                    bio_score = row.get('biological_score', 'N/A')
                    print(f"  {i:2d}. {seq:<20} (AI: {score:.3f}, Bio: {bio_score}, æ–¹æ³•: {method})")
    
    def analyze_sequence_diversity(self):
        """åˆ†æåºåˆ—å¤šæ ·æ€§"""
        print("\n" + "="*60)
        print("åºåˆ—å¤šæ ·æ€§åˆ†æ")
        print("="*60)
        
        def calculate_diversity_metrics(sequences):
            # è®¡ç®—åºåˆ—é•¿åº¦å¤šæ ·æ€§
            lengths = [len(seq) for seq in sequences]
            length_diversity = len(set(lengths))
            
            # è®¡ç®—æ°¨åŸºé…¸ç»„æˆå¤šæ ·æ€§
            all_aas = ''.join(sequences)
            aa_types = len(set(all_aas))
            
            # è®¡ç®—åºåˆ—ç‹¬ç‰¹æ€§
            unique_sequences = len(set(sequences))
            total_sequences = len(sequences)
            uniqueness = unique_sequences / total_sequences
            
            return {
                'length_diversity': length_diversity,
                'aa_types': aa_types,
                'uniqueness': uniqueness,
                'unique_count': unique_sequences,
                'total_count': total_sequences
            }
        
        # åˆ†ææ¯ç§æ–¹æ³•çš„å¤šæ ·æ€§
        methods = [
            ('åºåˆ—å˜å¼‚', self.seq_var_df['sequence'].tolist()),
            ('ç†æ€§è®¾è®¡', self.rational_df['sequence'].tolist()),
            ('VAEç”Ÿæˆ', self.vae_df['sequence'].tolist()),
            ('å…¨éƒ¨æ–¹æ³•', self.combined_df['sequence'].tolist())
        ]
        
        for method_name, sequences in methods:
            metrics = calculate_diversity_metrics(sequences)
            print(f"\nğŸ”¸ {method_name}:")
            print(f"  é•¿åº¦å¤šæ ·æ€§: {metrics['length_diversity']} ç§ä¸åŒé•¿åº¦")
            print(f"  æ°¨åŸºé…¸ç§ç±»: {metrics['aa_types']} ç§")
            print(f"  åºåˆ—ç‹¬ç‰¹æ€§: {metrics['uniqueness']:.1%} ({metrics['unique_count']}/{metrics['total_count']})")
    
    def generate_analysis_report(self):
        """ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š"""
        report_file = f"{self.results_dir}/detailed_analysis_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# å¤šè‚½å‘ç°ç»“æœè¯¦ç»†åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"**ç»“æœç›®å½•**: {self.results_dir}\n\n")
            
            # åŸºæœ¬ç»Ÿè®¡
            f.write("## ğŸ“Š åŸºæœ¬ç»Ÿè®¡\n\n")
            f.write(f"- åºåˆ—å˜å¼‚: {len(self.seq_var_df)} ä¸ªåºåˆ—\n")
            f.write(f"- ç†æ€§è®¾è®¡: {len(self.rational_df)} ä¸ªåºåˆ—\n")
            f.write(f"- VAEç”Ÿæˆ: {len(self.vae_df)} ä¸ªåºåˆ—\n")
            f.write(f"- **æ€»è®¡**: {len(self.combined_df)} ä¸ªå€™é€‰åºåˆ—\n\n")
            
            # AIé¢„æµ‹å¾—åˆ†ç»Ÿè®¡
            if 'predicted_activity' in self.combined_df.columns:
                ai_scores = self.combined_df['predicted_activity'].dropna()
                f.write("### ğŸ¤– AIé¢„æµ‹å¾—åˆ†åˆ†å¸ƒ\n\n")
                f.write(f"- å¹³å‡å¾—åˆ†: {ai_scores.mean():.3f}\n")
                f.write(f"- é«˜åˆ†åºåˆ— (>0.8): {sum(ai_scores > 0.8)} ä¸ª\n")
                f.write(f"- ä¸­åˆ†åºåˆ— (0.6-0.8): {sum((ai_scores >= 0.6) & (ai_scores <= 0.8))} ä¸ª\n")
                f.write(f"- ä½åˆ†åºåˆ— (<0.6): {sum(ai_scores < 0.6)} ä¸ª\n\n")
            
            # Topå€™é€‰åºåˆ— - ä¼˜å…ˆä½¿ç”¨AIé¢„æµ‹å¾—åˆ†
            f.write("## ğŸ¯ æ¨èå®éªŒå€™é€‰åºåˆ—\n\n")
            f.write("### ç¬¬ä¸€ä¼˜å…ˆçº§ (ç«‹å³åˆæˆéªŒè¯)\n\n")
            
            # å…¨å±€Top 15ï¼ˆåŸºäºAIé¢„æµ‹å¾—åˆ†ï¼‰
            if 'predicted_activity' in self.combined_df.columns:
                valid_ai = self.combined_df[self.combined_df['predicted_activity'].notna()]
                if len(valid_ai) > 0:
                    global_top15 = valid_ai.nlargest(15, 'predicted_activity')
                    f.write("#### å…¨å±€Top 15 (åŸºäºAIé¢„æµ‹æ´»æ€§):\n\n")
                    for i, (_, row) in enumerate(global_top15.iterrows(), 1):
                        seq = row['sequence']
                        ai_score = row['predicted_activity']
                        bio_score = row.get('biological_score', 'N/A')
                        method = row['method']
                        f.write(f"{i}. `{seq}` (AI: {ai_score:.3f}, Bio: {bio_score}, æ¥æº: {method})\n")
                    f.write("\n")
            
            # åˆ†æ–¹æ³•Top 5
            for method, method_name in [('sequence_variation', 'åºåˆ—å˜å¼‚'), 
                                      ('rational_design', 'ç†æ€§è®¾è®¡'), 
                                      ('vae_generation', 'VAEç”Ÿæˆ')]:
                if method == 'rational_design':
                    method_df = self.combined_df[self.combined_df['method'].str.contains('rational_design')]
                else:
                    method_df = self.combined_df[self.combined_df['method'] == method]
                
                if len(method_df) == 0:
                    continue
                    
                f.write(f"\n#### {method_name} Top 5:\n")
                
                # ä¼˜å…ˆä½¿ç”¨AIé¢„æµ‹å¾—åˆ†
                if 'predicted_activity' in method_df.columns:
                    valid_scores = method_df[method_df['predicted_activity'].notna()]
                    if len(valid_scores) > 0:
                        top_5 = valid_scores.nlargest(5, 'predicted_activity')
                    else:
                        top_5 = method_df.head(5)
                elif 'biological_score' in method_df.columns:
                    top_5 = method_df.nlargest(5, 'biological_score')
                else:
                    top_5 = method_df.head(5)
                
                for i, (_, row) in enumerate(top_5.iterrows(), 1):
                    seq = row['sequence']
                    ai_score = row.get('predicted_activity', 'N/A')
                    bio_score = row.get('biological_score', 'N/A')
                    f.write(f"{i}. `{seq}` (AI: {ai_score}, Bio: {bio_score})\n")
            
            # åˆ†æå»ºè®®
            f.write("\n## ğŸ’¡ åˆ†æå»ºè®®\n\n")
            f.write("### å®éªŒè®¾è®¡å»ºè®®\n")
            f.write("1. **ç¬¬ä¸€æ‰¹å®éªŒ**: é€‰æ‹©å…¨å±€Top 15åºåˆ—è¿›è¡ŒåˆæˆéªŒè¯\n")
            f.write("2. **å¯¹ç…§ç»„**: åŒ…å«2-3ä¸ªå·²çŸ¥æ´»æ€§åºåˆ—\n") 
            f.write("3. **æµ“åº¦èŒƒå›´**: å»ºè®®æµ‹è¯•1-128 Î¼g/mL\n")
            f.write("4. **ç»†èŒæ ª**: åŒ…å«é©å…°æ°é˜³æ€§å’Œé˜´æ€§èŒ\n\n")
            
            f.write("### è¯„åˆ†æ ‡å‡†è¯´æ˜\n")
            f.write("- **AIé¢„æµ‹æ´»æ€§**: åŸºäºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„é¢„æµ‹å¾—åˆ† (0-1)\n")
            f.write("- **ç”Ÿç‰©å­¦è¯„åˆ†**: åŸºäºç†åŒ–æ€§è´¨å’Œç”Ÿç‰©å­¦çŸ¥è¯†çš„è¯„åˆ† (0-100)\n")
            f.write("- **å»ºè®®ä¼˜å…ˆçº§**: AIé¢„æµ‹æ´»æ€§ > ç”Ÿç‰©å­¦è¯„åˆ† > åºåˆ—ç‰¹å¾\n\n")
            
            f.write("### åç»­ä¼˜åŒ–æ–¹å‘\n")
            f.write("- æ ¹æ®å®éªŒç»“æœè°ƒæ•´AIæ¨¡å‹å‚æ•°\n")
            f.write("- åˆ†ææˆåŠŸåºåˆ—çš„å…±åŒç‰¹å¾\n")
            f.write("- æ”¶é›†å®éªŒåé¦ˆè¿›è¡Œæ¨¡å‹å¾®è°ƒ\n")
            f.write("- æ‰©å±•åˆ°æ›´å¤šç»†èŒæ ªæµ‹è¯•\n")
        
        print(f"\nâœ… è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def add_unified_ai_scores(self):
        """ä¸ºæ‰€æœ‰åºåˆ—æ·»åŠ ç»Ÿä¸€çš„AIé¢„æµ‹å¾—åˆ†"""
        print("\nğŸ¤– æ­£åœ¨ä¸ºæ‰€æœ‰åºåˆ—è®¡ç®—AIé¢„æµ‹å¾—åˆ†...")
        
        try:
            # å¯¼å…¥é¢„æµ‹æ¨¡å—
            import sys
            sys.path.append('src')
            from predict_peptide import PeptidePredictionPipeline
            
            # åˆå§‹åŒ–é¢„æµ‹å™¨
            predictor = PeptidePredictionPipeline()
            
            # ä¸ºåˆå¹¶æ•°æ®é›†æ·»åŠ AIå¾—åˆ†
            sequences = self.combined_df['sequence'].tolist()
            ai_scores = []
            
            for i, seq in enumerate(sequences):
                if i % 10 == 0:
                    print(f"   è¿›åº¦: {i+1}/{len(sequences)}")
                
                try:
                    score = predictor.predict_single(seq)
                    ai_scores.append(score)
                except Exception as e:
                    print(f"   è­¦å‘Š: åºåˆ— {seq} é¢„æµ‹å¤±è´¥: {e}")
                    ai_scores.append(0.0)  # é»˜è®¤ä½åˆ†
            
            # æ·»åŠ AIå¾—åˆ†åˆ—
            self.combined_df['ai_prediction_score'] = ai_scores
            
            # ä¸ºå„ä¸ªå­æ•°æ®é›†ä¹Ÿæ·»åŠ AIå¾—åˆ†
            seq_var_sequences = self.seq_var_df['sequence'].tolist()
            rational_sequences = self.rational_df['sequence'].tolist()
            vae_sequences = self.vae_df['sequence'].tolist()
            
            # ä»åˆå¹¶æ•°æ®é›†ä¸­æå–å¯¹åº”å¾—åˆ†
            self.seq_var_df['ai_prediction_score'] = [
                self.combined_df[self.combined_df['sequence'] == seq]['ai_prediction_score'].iloc[0]
                for seq in seq_var_sequences
            ]
            
            self.rational_df['ai_prediction_score'] = [
                self.combined_df[self.combined_df['sequence'] == seq]['ai_prediction_score'].iloc[0]
                for seq in rational_sequences
            ]
            
            self.vae_df['ai_prediction_score'] = [
                self.combined_df[self.combined_df['sequence'] == seq]['ai_prediction_score'].iloc[0]
                for seq in vae_sequences
            ]
            
            print(f"âœ… AIè¯„åˆ†å®Œæˆ! å¹³å‡å¾—åˆ†: {np.mean(ai_scores):.3f}")
            print(f"   é«˜åˆ†åºåˆ— (>0.8): {sum(1 for s in ai_scores if s > 0.8)} ä¸ª")
            print(f"   ä¸­åˆ†åºåˆ— (0.6-0.8): {sum(1 for s in ai_scores if 0.6 <= s <= 0.8)} ä¸ª")
            print(f"   ä½åˆ†åºåˆ— (<0.6): {sum(1 for s in ai_scores if s < 0.6)} ä¸ª")
            
        except Exception as e:
            print(f"âš ï¸ AIè¯„åˆ†å¤±è´¥: {e}")
            print("   å°†ä½¿ç”¨ç°æœ‰è¯„åˆ†è¿›è¡Œåˆ†æ")
            return False
        
        return True
    
    def _calculate_net_charge(self, sequence):
        """è®¡ç®—å‡€ç”µè·"""
        positive = sequence.count('K') + sequence.count('R') + sequence.count('H')
        negative = sequence.count('D') + sequence.count('E')
        return positive - negative
    
    def _calculate_hydrophobic_ratio(self, sequence):
        """è®¡ç®—ç–æ°´æ€§æ°¨åŸºé…¸æ¯”ä¾‹"""
        hydrophobic = sum(1 for aa in sequence if aa in 'AILMFWYV')
        return hydrophobic / len(sequence)
    
    def _calculate_aromatic_ratio(self, sequence):
        """è®¡ç®—èŠ³é¦™æ—æ°¨åŸºé…¸æ¯”ä¾‹"""
        aromatic = sum(1 for aa in sequence if aa in 'FWY')
        return aromatic / len(sequence)

def main():
    """ä¸»åˆ†æå‡½æ•°"""
    import argparse
    import glob
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å¤šè‚½å‘ç°ç»“æœåˆ†æå·¥å…·')
    parser.add_argument('--results_dir', type=str, help='æŒ‡å®šç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--include_plots', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    parser.add_argument('--plot_format', default='png', choices=['png', 'pdf', 'svg'], help='å›¾è¡¨æ ¼å¼')
    args = parser.parse_args()
    
    # ç¡®å®šåˆ†æç›®å½•
    if args.results_dir:
        if not os.path.exists(args.results_dir):
            print(f"âŒ æŒ‡å®šçš„ç»“æœç›®å½•ä¸å­˜åœ¨: {args.results_dir}")
            return
        latest_dir = args.results_dir
        print(f"ğŸ” åˆ†ææŒ‡å®šç›®å½•: {latest_dir}")
    else:
        # ä½¿ç”¨æœ€æ–°çš„ç»“æœç›®å½•
        result_dirs = glob.glob('results_three_methods_*')
        if not result_dirs:
            print("âŒ æœªæ‰¾åˆ°ç»“æœç›®å½•ï¼è¯·å…ˆè¿è¡Œ three_method_discovery.py")
            return
        latest_dir = sorted(result_dirs)[-1]  # é€‰æ‹©æœ€æ–°çš„ç»“æœ
        print(f"ğŸ” åˆ†ææœ€æ–°ç›®å½•: {latest_dir}")
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œåˆ†æ
    analyzer = PeptideResultAnalyzer(latest_dir)
    
    if not analyzer.load_data():
        return
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    analyzer.analyze_amino_acid_usage()
    analyzer.analyze_sequence_properties()
    analyzer.find_top_candidates(top_n=10)
    analyzer.analyze_sequence_diversity()
    analyzer.generate_analysis_report()
    
    print("\n" + "="*60)
    print("ğŸ‰ åˆ†æå®Œæˆï¼")
    print("="*60)
    print("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š:")
    print(f"   {latest_dir}/detailed_analysis_report.md")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. æ ¹æ®æŠ¥å‘Šé€‰æ‹©å®éªŒå€™é€‰åºåˆ—")
    print("2. è®¾è®¡åˆæˆå’Œæ´»æ€§æµ‹è¯•å®éªŒ")
    print("3. æ”¶é›†å®éªŒåé¦ˆä¼˜åŒ–æ¨¡å‹")

if __name__ == "__main__":
    main()
